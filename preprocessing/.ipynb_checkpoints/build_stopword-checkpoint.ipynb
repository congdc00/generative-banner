{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a41221e-dbff-41ac-a719-c566162fc6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e380577a-e9f4-44bb-9a57-ee666263e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/congdc/Project/generative-banner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "642a5161-403d-4bcf-bb2d-cce0cbc3b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from utils.translate import Translater\n",
    "import pandas as pd\n",
    "from core.stable_diffusion import SD_Model\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import underthesea\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f0d0abd-51b6-4bca-ad2c-3cc036209b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH  = \"./data/train/target/\"\n",
    "TEST_PATH = \"./data/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f2369d0-f02c-4e0f-abc9-1665f28def76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f\"{TRAIN_PATH}info.csv\")\n",
    "id_imgs_train = list(df_train[\"id\"])\n",
    "captions_train = list(df_train['caption'])\n",
    "description_train = list(df_train['description'])\n",
    "moreInfo_train = list(df_train['moreInfo'])\n",
    "bannerImages_train = list(df_train['bannerImage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ee9f5a1-2fdc-43c9-b8bc-91c671f6ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(f\"{TEST_PATH}info.csv\")\n",
    "id_imgs_test = list(df_test[\"id\"])\n",
    "captions_test = list(df_test['caption'])\n",
    "description_test = list(df_test['description'])\n",
    "moreInfo_test = list(df_test['moreInfo'])\n",
    "bannerImages_test = list(df_test['bannerImage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d42ffc3a-ae6a-46d6-aecb-95ad6639a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stopwords(content):\n",
    "    cleaned_text = re.sub(r'\\W', ' ', content)\n",
    "    cleaned_text = re.sub(r'\\b\\w\\b', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\d', '', cleaned_text)\n",
    "    \n",
    "    words = text_segment.split()\n",
    "    word_counter = Counter(words)\n",
    "    return word_counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "eba78a7f-d2ec-4599-94fe-d227e5b35d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(list_sentence):\n",
    "    # dict_token = [\n",
    "    #     # [\"bạt phủ\", \"vải phủ\", \"áo phủ\", \"bạt trùm\"],\n",
    "    #     # [\"thảm lót sàn\", \"thảm sàn\", \"thảm trải sàn\", \"thảm da lót sàn\"],\n",
    "    #     # [\"lốp ô tô\", \"vỏ ô tô\"],\n",
    "    #     # [\"xe\", \"ô tô\", \"xế\", \"oto\"],\n",
    "    #     # [\"sang trọng\",\"lịch lãm\"],\n",
    "    #     # [\"loại\", \"dòng\"],\n",
    "    #     # [\"máy ảnh\", \"camera\"],\n",
    "    #     # [\"\", \"chỗ\", \"độ\"],\n",
    "    #     # [\"răng sứ\"]\n",
    "    # ]\n",
    "    \n",
    "    list_sentence_tokened = []\n",
    "    for sentence in list_sentence:\n",
    "        \n",
    "        # custom_token\n",
    "        # for list_key in dict_token:\n",
    "        #     first_key = \"_\".join(list_key[0].split())\n",
    "        #     second_keys = list_key\n",
    "\n",
    "        #     for key in second_keys:\n",
    "        #         if key in sentence:\n",
    "        #             sentence = sentence.replace(key, first_key)\n",
    "        \n",
    "        sentence = underthesea.word_tokenize(sentence, format=\"text\")\n",
    "        \n",
    "                \n",
    "        list_sentence_tokened.append(sentence)\n",
    "    return list_sentence_tokened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "c74423d6-0a82-461b-bdc1-d6e76ca819b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_nouns(list_sentence):\n",
    "    list_new_sentence = []\n",
    "    for i, sentence in enumerate(list_sentence):\n",
    "        new_sentence = []\n",
    "        # print(sentence)\n",
    "        for word, tag in underthesea.pos_tag(sentence):\n",
    "            if tag == 'N' or tag == \"NP\":\n",
    "                new_sentence.append(word)\n",
    "                \n",
    "        new_sentence = \" \".join(new_sentence)\n",
    "        list_new_sentence.append(new_sentence)\n",
    "    return list_new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "f364a919-b04e-4383-9d8b-e1d41e0d12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_tf_idf_score(list_sentence):\n",
    "\n",
    "    NUM_TOP = 6\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(list_sentence)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    list_result = []\n",
    "    for i, sentence in tqdm(enumerate(list_sentence)):\n",
    "        # print(sentence)\n",
    "        list_word = []\n",
    "        for j, word in enumerate(feature_names):\n",
    "            tfidf_value = tfidf_matrix[i, j]\n",
    "            if tfidf_value > 0:\n",
    "                list_word.append([word, tfidf_value])\n",
    "        sorted_indices = [[word, value] for word, value in sorted(list_word, key=lambda x: x[1], reverse=True)]\n",
    "\n",
    "        # for i in range(len(sorted_indices[:NUM_TOP])):\n",
    "        #     word = sorted_indices[i][0]\n",
    "        #     word = word.replace(\"_\", \" \")\n",
    "        #     word = Translater.vie2eng(word)\n",
    "        #     sorted_indices[i] = word\n",
    "        \n",
    "        list_result.append(sorted_indices)\n",
    "    return list_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "3e9b1334-e9a3-4921-8126-8c6559d12eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(list_sentence):\n",
    "    list_result = []\n",
    "    for sentence in tqdm(list_sentence):\n",
    "        sentence = str(sentence).lower()\n",
    "        sentence = re.sub(r'\\W', ' ', sentence)\n",
    "        sentence = re.sub(r'\\d', '', sentence)\n",
    "        #sentence = Translater.vie2eng(sentence) \n",
    "        \n",
    "        list_result.append(sentence)\n",
    "        \n",
    "        \n",
    "    return list_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "57e341e4-0804-47e0-ad75-0936c47133ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple red', 'banana yellow', 'orange orange']"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = [\"apple\", \"banana\", \"orange\"]\n",
    "list2 = [\"red\", \"yellow\", \"orange\"]\n",
    "\n",
    "result_list = []\n",
    "for elem1, elem2 in zip(list1, list2):\n",
    "    result_list.append(elem1 + \" \" + elem2)\n",
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "c8e1d960-b663-4af2-8595-34f5c6dfe31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = []\n",
    "for elem1, elem2, elem3 in zip(captions_train, description_train, moreInfo_train):\n",
    "    data_train.append(str(elem1) + \". \" + str(elem2) + \". \" + str(elem3))\n",
    "\n",
    "data_test = []\n",
    "for elem1, elem2, elem3 in zip(captions_test, description_test, moreInfo_test):\n",
    "    data_train.append(str(elem1) + \". \" + str(elem2) + \". \" + str(elem3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "c7b4d35d-32b2-4365-91ec-75f8537b6da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 2100/2100 [00:00<00:00, 106773.16it/s]\n"
     ]
    }
   ],
   "source": [
    "list_content = data_train + data_test\n",
    "list_content = format_data(list_content)\n",
    "list_content= tokenization(list_content)\n",
    "list_content = select_nouns(list_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "31747aa1-a2a4-42d9-8e3f-4f922e829dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyword(list_content):\n",
    "\n",
    "    list_products = [\n",
    "        [\"bạt phủ\", \"vải phủ\", \"áo phủ\", \"bạt trùm\"],\n",
    "        [\"thảm lót sàn\", \"thảm sàn\", \"thảm trải sàn\", \"thảm da lót sàn\"],\n",
    "        [\"lốp ô tô\", \"vỏ ô tô\"],\n",
    "        # [\"xe\", \"ô tô\", \"xế\", \"oto\"],\n",
    "        [\"sang trọng\",\"lịch lãm\"],\n",
    "        [\"răng sứ\"]\n",
    "    ]\n",
    "\n",
    "    list_lable = []\n",
    "    for content in list_content:\n",
    "        product = \"\"\n",
    "        for list_p in list_products:\n",
    "            name_product = list_p[0]\n",
    "            for p in list_p:\n",
    "\n",
    "                if \"-\" not in p:\n",
    "                    if p in content:\n",
    "                        product += name_product\n",
    "                        break\n",
    "                else:\n",
    "                    list_k = p.split(\"-\")\n",
    "                    exist_ok = True\n",
    "                    for k in list_k:\n",
    "                        if k not in content:\n",
    "                            exist_ok = False\n",
    "                            break\n",
    "                    if exist_ok:\n",
    "                        product += name_product\n",
    "\n",
    "                if product != \"\":\n",
    "                    break\n",
    "                    \n",
    "            if product != \"\":\n",
    "                break  \n",
    "                    \n",
    "        list_lable.append(product)\n",
    "    return list_lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "1d0bdad2-4ed1-42ac-9103-f8b68d393f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_key = get_keyword(list_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "b9a7d29c-edaf-43ec-bceb-fc1050b83c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 2075 lần\n",
      "bạt phủ: 4 lần\n",
      "lốp ô tô: 1 lần\n",
      "răng sứ: 19 lần\n",
      "thảm lót sàn: 1 lần\n"
     ]
    }
   ],
   "source": [
    "element_counts = Counter(list_key)\n",
    "for element, count in element_counts.items():\n",
    "    print(f\"{element}: {count} lần\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1c6a4-2957-42d5-9db3-05507b8746d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
